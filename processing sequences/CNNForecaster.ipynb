{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_type</th>\n",
       "      <th>bus</th>\n",
       "      <th>rail</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>U</td>\n",
       "      <td>297192</td>\n",
       "      <td>126455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>W</td>\n",
       "      <td>780827</td>\n",
       "      <td>501952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>W</td>\n",
       "      <td>824923</td>\n",
       "      <td>536432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>W</td>\n",
       "      <td>870021</td>\n",
       "      <td>550011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>W</td>\n",
       "      <td>890426</td>\n",
       "      <td>557917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-27</th>\n",
       "      <td>U</td>\n",
       "      <td>312965</td>\n",
       "      <td>215594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-28</th>\n",
       "      <td>W</td>\n",
       "      <td>611041</td>\n",
       "      <td>389359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-29</th>\n",
       "      <td>W</td>\n",
       "      <td>652674</td>\n",
       "      <td>444706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-30</th>\n",
       "      <td>W</td>\n",
       "      <td>657942</td>\n",
       "      <td>451915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31</th>\n",
       "      <td>W</td>\n",
       "      <td>605292</td>\n",
       "      <td>425596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8705 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           day_type     bus    rail\n",
       "date                               \n",
       "2001-01-01        U  297192  126455\n",
       "2001-01-02        W  780827  501952\n",
       "2001-01-03        W  824923  536432\n",
       "2001-01-04        W  870021  550011\n",
       "2001-01-05        W  890426  557917\n",
       "...             ...     ...     ...\n",
       "2024-10-27        U  312965  215594\n",
       "2024-10-28        W  611041  389359\n",
       "2024-10-29        W  652674  444706\n",
       "2024-10-30        W  657942  451915\n",
       "2024-10-31        W  605292  425596\n",
       "\n",
       "[8705 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "path = Path(\"C:\\\\Users\\\\manch\\\\OneDrive\\\\Documents\\\\DEV\\\\MachineLearning\\\\datasets\\\\CTA_-_Ridership_-_Daily_Boarding_Totals_20241230.csv\")\n",
    "\n",
    "df = pd.read_csv(path, parse_dates=[\"service_date\"])\n",
    "df.columns = [\"date\", \"day_type\", \"bus\", \"rail\", \"total\"] #shorter names\n",
    "df = df.sort_values(\"date\").set_index(\"date\")\n",
    "df = df.drop(\"total\", axis=1) # no need for total, it's just bus+ rail\n",
    "df = df.drop_duplicates() # remove duplicated months (2011-10and 2014-07)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_windows(dataset, length):\n",
    "    dataset = dataset.window(length, shift=1,drop_remainder=True)\n",
    "    return dataset.flat_map(lambda window_ds:window_ds.batch(length))\n",
    "\n",
    "def to_seq2seq_dataset( series, \n",
    "                        seq_length=56, \n",
    "                        ahead=14,\n",
    "                        target_col=1,\n",
    "                        batch_size=32, \n",
    "                        shuffle=False, \n",
    "                        seed=None):\n",
    "    ds = to_windows(tf.data.Dataset.from_tensor_slices(series),ahead + 1)\n",
    "    ds = to_windows(ds, seq_length).map(lambda S: (S[:, 0], S[:,1:, 1]))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(8 * batch_size, seed=seed)\n",
    "    return ds.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "df_mulvar                   = df[[\"bus\", \"rail\"]] / 1e6 # use both bus & rail series as input\n",
    "df_mulvar[\"next_day_type\"]  = df[\"day_type\"].shift(-1)  # we know tomorrow's type\n",
    "df_mulvar                   = pd.get_dummies(df_mulvar) # one-hot encode the day type Now df_mulvar is a DataFrame with five columns: the bus and rail data,\n",
    "                                                        # plus three columns containing the one-hot encoding of the next day’s type\n",
    "                                                        # (recall that there are three possible day types, W, A, and U).\n",
    "\n",
    "#Split the data into three periods. For training, validation, and testing:\n",
    "mulvar_train = df_mulvar[\"2016-01\":\"2018-12\"]\n",
    "mulvar_valid = df_mulvar[\"2019-01\":\"2019-05\"]\n",
    "mulvar_test  = df_mulvar[\"2019-06\":]\n",
    "\n",
    "# Ensure all columns are numeric, converting booleans to float32\n",
    "mulvar_train = mulvar_train.astype(np.float32)\n",
    "mulvar_valid = mulvar_valid.astype(np.float32)\n",
    "mulvar_test  = mulvar_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manch\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conv_rnn_model = tf.keras.Sequential(\n",
    "                                        [\n",
    "                                            tf.keras.layers.Conv1D( filters=32, \n",
    "                                                                    kernel_size=4, \n",
    "                                                                    strides=2,\n",
    "                                                                    activation=\"relu\", \n",
    "                                                                    input_shape=[None,5]\n",
    "                                                                    ),\n",
    "                                            tf.keras.layers.GRU(32, return_sequences=True),\n",
    "                                            tf.keras.layers.Dense(14)\n",
    "                                        ]\n",
    "                                    )\n",
    "longer_train = to_seq2seq_dataset(mulvar_train, seq_length=112,shuffle=True, seed=42)\n",
    "longer_valid = to_seq2seq_dataset(mulvar_valid, seq_length=112)\n",
    "\n",
    "downsampled_train = longer_train.map(lambda X, Y: (X, Y[:,3::2]))\n",
    "downsampled_valid = longer_valid.map(lambda X, Y: (X, Y[:,3::2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     31/Unknown \u001b[1m9s\u001b[0m 62ms/step - loss: 0.1402 - mae: 0.4636"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manch\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 102ms/step - loss: 0.1384 - mae: 0.4592 - val_loss: 0.0258 - val_mae: 0.1624\n",
      "Epoch 2/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0191 - mae: 0.1558 - val_loss: 0.0183 - val_mae: 0.1534\n",
      "Epoch 3/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0168 - mae: 0.1557 - val_loss: 0.0178 - val_mae: 0.1495\n",
      "Epoch 4/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0163 - mae: 0.1536 - val_loss: 0.0174 - val_mae: 0.1467\n",
      "Epoch 5/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0158 - mae: 0.1507 - val_loss: 0.0170 - val_mae: 0.1445\n",
      "Epoch 6/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0153 - mae: 0.1480 - val_loss: 0.0165 - val_mae: 0.1422\n",
      "Epoch 7/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0149 - mae: 0.1458 - val_loss: 0.0161 - val_mae: 0.1401\n",
      "Epoch 8/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0146 - mae: 0.1438 - val_loss: 0.0157 - val_mae: 0.1377\n",
      "Epoch 9/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0141 - mae: 0.1410 - val_loss: 0.0153 - val_mae: 0.1353\n",
      "Epoch 10/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0138 - mae: 0.1385 - val_loss: 0.0149 - val_mae: 0.1332\n",
      "Epoch 11/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0134 - mae: 0.1362 - val_loss: 0.0146 - val_mae: 0.1307\n",
      "Epoch 12/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - loss: 0.0129 - mae: 0.1330 - val_loss: 0.0141 - val_mae: 0.1290\n",
      "Epoch 13/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 166ms/step - loss: 0.0127 - mae: 0.1315 - val_loss: 0.0138 - val_mae: 0.1265\n",
      "Epoch 14/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - loss: 0.0123 - mae: 0.1289 - val_loss: 0.0134 - val_mae: 0.1243\n",
      "Epoch 15/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 190ms/step - loss: 0.0119 - mae: 0.1261 - val_loss: 0.0130 - val_mae: 0.1224\n",
      "Epoch 16/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - loss: 0.0116 - mae: 0.1239 - val_loss: 0.0127 - val_mae: 0.1202\n",
      "Epoch 17/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0113 - mae: 0.1216 - val_loss: 0.0124 - val_mae: 0.1182\n",
      "Epoch 18/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0110 - mae: 0.1196 - val_loss: 0.0121 - val_mae: 0.1164\n",
      "Epoch 19/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0107 - mae: 0.1169 - val_loss: 0.0118 - val_mae: 0.1148\n",
      "Epoch 20/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0103 - mae: 0.1146 - val_loss: 0.0115 - val_mae: 0.1132\n",
      "Epoch 21/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0101 - mae: 0.1131 - val_loss: 0.0112 - val_mae: 0.1117\n",
      "Epoch 22/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0100 - mae: 0.1118 - val_loss: 0.0110 - val_mae: 0.1103\n",
      "Epoch 23/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0097 - mae: 0.1095 - val_loss: 0.0107 - val_mae: 0.1090\n",
      "Epoch 24/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0094 - mae: 0.1080 - val_loss: 0.0105 - val_mae: 0.1078\n",
      "Epoch 25/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0093 - mae: 0.1066 - val_loss: 0.0103 - val_mae: 0.1066\n",
      "Epoch 26/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0090 - mae: 0.1046 - val_loss: 0.0101 - val_mae: 0.1055\n",
      "Epoch 27/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0089 - mae: 0.1038 - val_loss: 0.0099 - val_mae: 0.1045\n",
      "Epoch 28/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0087 - mae: 0.1023 - val_loss: 0.0097 - val_mae: 0.1035\n",
      "Epoch 29/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0086 - mae: 0.1017 - val_loss: 0.0095 - val_mae: 0.1026\n",
      "Epoch 30/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0085 - mae: 0.1007 - val_loss: 0.0094 - val_mae: 0.1016\n",
      "Epoch 31/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0083 - mae: 0.0994 - val_loss: 0.0092 - val_mae: 0.1008\n",
      "Epoch 32/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0081 - mae: 0.0982 - val_loss: 0.0091 - val_mae: 0.1000\n",
      "Epoch 33/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0080 - mae: 0.0971 - val_loss: 0.0089 - val_mae: 0.0992\n",
      "Epoch 34/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0080 - mae: 0.0970 - val_loss: 0.0088 - val_mae: 0.0985\n",
      "Epoch 35/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0078 - mae: 0.0956 - val_loss: 0.0087 - val_mae: 0.0977\n",
      "Epoch 36/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0077 - mae: 0.0950 - val_loss: 0.0086 - val_mae: 0.0970\n",
      "Epoch 37/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0077 - mae: 0.0949 - val_loss: 0.0085 - val_mae: 0.0964\n",
      "Epoch 38/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0074 - mae: 0.0934 - val_loss: 0.0084 - val_mae: 0.0957\n",
      "Epoch 39/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0074 - mae: 0.0928 - val_loss: 0.0083 - val_mae: 0.0952\n",
      "Epoch 40/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 0.0073 - mae: 0.0922 - val_loss: 0.0082 - val_mae: 0.0945\n",
      "Epoch 41/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0072 - mae: 0.0915 - val_loss: 0.0081 - val_mae: 0.0939\n",
      "Epoch 42/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0071 - mae: 0.0908 - val_loss: 0.0080 - val_mae: 0.0933\n",
      "Epoch 43/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0071 - mae: 0.0904 - val_loss: 0.0079 - val_mae: 0.0928\n",
      "Epoch 44/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0070 - mae: 0.0899 - val_loss: 0.0078 - val_mae: 0.0922\n",
      "Epoch 45/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0068 - mae: 0.0887 - val_loss: 0.0078 - val_mae: 0.0918\n",
      "Epoch 46/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0068 - mae: 0.0885 - val_loss: 0.0077 - val_mae: 0.0911\n",
      "Epoch 47/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0067 - mae: 0.0878 - val_loss: 0.0076 - val_mae: 0.0906\n",
      "Epoch 48/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0067 - mae: 0.0876 - val_loss: 0.0075 - val_mae: 0.0900\n",
      "Epoch 49/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0067 - mae: 0.0873 - val_loss: 0.0075 - val_mae: 0.0897\n",
      "Epoch 50/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0065 - mae: 0.0861 - val_loss: 0.0074 - val_mae: 0.0890\n",
      "Epoch 51/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0066 - mae: 0.0863 - val_loss: 0.0074 - val_mae: 0.0887\n",
      "Epoch 52/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0064 - mae: 0.0852 - val_loss: 0.0073 - val_mae: 0.0882\n",
      "Epoch 53/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0064 - mae: 0.0851 - val_loss: 0.0072 - val_mae: 0.0876\n",
      "Epoch 54/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0064 - mae: 0.0849 - val_loss: 0.0072 - val_mae: 0.0872\n",
      "Epoch 55/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0063 - mae: 0.0843 - val_loss: 0.0071 - val_mae: 0.0867\n",
      "Epoch 56/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0063 - mae: 0.0838 - val_loss: 0.0071 - val_mae: 0.0862\n",
      "Epoch 57/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0061 - mae: 0.0829 - val_loss: 0.0070 - val_mae: 0.0858\n",
      "Epoch 58/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0061 - mae: 0.0829 - val_loss: 0.0069 - val_mae: 0.0851\n",
      "Epoch 59/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0061 - mae: 0.0825 - val_loss: 0.0069 - val_mae: 0.0846\n",
      "Epoch 60/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0061 - mae: 0.0824 - val_loss: 0.0068 - val_mae: 0.0843\n",
      "Epoch 61/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0059 - mae: 0.0808 - val_loss: 0.0068 - val_mae: 0.0838\n",
      "Epoch 62/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0059 - mae: 0.0808 - val_loss: 0.0067 - val_mae: 0.0833\n",
      "Epoch 63/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0059 - mae: 0.0803 - val_loss: 0.0067 - val_mae: 0.0827\n",
      "Epoch 64/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0058 - mae: 0.0798 - val_loss: 0.0066 - val_mae: 0.0823\n",
      "Epoch 65/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0058 - mae: 0.0794 - val_loss: 0.0065 - val_mae: 0.0817\n",
      "Epoch 66/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0057 - mae: 0.0792 - val_loss: 0.0065 - val_mae: 0.0813\n",
      "Epoch 67/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0057 - mae: 0.0787 - val_loss: 0.0065 - val_mae: 0.0807\n",
      "Epoch 68/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0056 - mae: 0.0781 - val_loss: 0.0064 - val_mae: 0.0803\n",
      "Epoch 69/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0056 - mae: 0.0775 - val_loss: 0.0064 - val_mae: 0.0797\n",
      "Epoch 70/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0055 - mae: 0.0772 - val_loss: 0.0063 - val_mae: 0.0793\n",
      "Epoch 71/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0055 - mae: 0.0768 - val_loss: 0.0063 - val_mae: 0.0787\n",
      "Epoch 72/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0055 - mae: 0.0767 - val_loss: 0.0062 - val_mae: 0.0783\n",
      "Epoch 73/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 0.0053 - mae: 0.0755 - val_loss: 0.0062 - val_mae: 0.0777\n",
      "Epoch 74/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0054 - mae: 0.0754 - val_loss: 0.0061 - val_mae: 0.0774\n",
      "Epoch 75/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0053 - mae: 0.0749 - val_loss: 0.0061 - val_mae: 0.0766\n",
      "Epoch 76/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0054 - mae: 0.0751 - val_loss: 0.0060 - val_mae: 0.0763\n",
      "Epoch 77/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0053 - mae: 0.0742 - val_loss: 0.0060 - val_mae: 0.0759\n",
      "Epoch 78/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0052 - mae: 0.0734 - val_loss: 0.0059 - val_mae: 0.0754\n",
      "Epoch 79/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - loss: 0.0052 - mae: 0.0736 - val_loss: 0.0059 - val_mae: 0.0749\n",
      "Epoch 80/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 0.0052 - mae: 0.0729 - val_loss: 0.0059 - val_mae: 0.0746\n",
      "Epoch 81/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0050 - mae: 0.0719 - val_loss: 0.0058 - val_mae: 0.0740\n",
      "Epoch 82/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0051 - mae: 0.0723 - val_loss: 0.0058 - val_mae: 0.0738\n",
      "Epoch 83/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.0050 - mae: 0.0717 - val_loss: 0.0057 - val_mae: 0.0732\n",
      "Epoch 84/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 140ms/step - loss: 0.0050 - mae: 0.0711 - val_loss: 0.0057 - val_mae: 0.0728\n",
      "Epoch 85/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0049 - mae: 0.0706 - val_loss: 0.0056 - val_mae: 0.0721\n",
      "Epoch 86/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0050 - mae: 0.0707 - val_loss: 0.0056 - val_mae: 0.0720\n",
      "Epoch 87/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0049 - mae: 0.0696 - val_loss: 0.0056 - val_mae: 0.0715\n",
      "Epoch 88/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0048 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0709\n",
      "Epoch 89/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0048 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0707\n",
      "Epoch 90/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - loss: 0.0047 - mae: 0.0684 - val_loss: 0.0054 - val_mae: 0.0701\n",
      "Epoch 91/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0048 - mae: 0.0685 - val_loss: 0.0054 - val_mae: 0.0700\n",
      "Epoch 92/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0047 - mae: 0.0679 - val_loss: 0.0054 - val_mae: 0.0693\n",
      "Epoch 93/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0047 - mae: 0.0676 - val_loss: 0.0053 - val_mae: 0.0689\n",
      "Epoch 94/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0047 - mae: 0.0674 - val_loss: 0.0053 - val_mae: 0.0687\n",
      "Epoch 95/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0046 - mae: 0.0668 - val_loss: 0.0052 - val_mae: 0.0680\n",
      "Epoch 96/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0046 - mae: 0.0666 - val_loss: 0.0052 - val_mae: 0.0679\n",
      "Epoch 97/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0045 - mae: 0.0657 - val_loss: 0.0052 - val_mae: 0.0675\n",
      "Epoch 98/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0046 - mae: 0.0660 - val_loss: 0.0052 - val_mae: 0.0673\n",
      "Epoch 99/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0045 - mae: 0.0653 - val_loss: 0.0051 - val_mae: 0.0670\n",
      "Epoch 100/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0046 - mae: 0.0655 - val_loss: 0.0051 - val_mae: 0.0666\n",
      "Epoch 101/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0045 - mae: 0.0648 - val_loss: 0.0050 - val_mae: 0.0659\n",
      "Epoch 102/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0045 - mae: 0.0647 - val_loss: 0.0050 - val_mae: 0.0659\n",
      "Epoch 103/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0044 - mae: 0.0642 - val_loss: 0.0050 - val_mae: 0.0654\n",
      "Epoch 104/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0044 - mae: 0.0640 - val_loss: 0.0050 - val_mae: 0.0653\n",
      "Epoch 105/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - loss: 0.0044 - mae: 0.0634 - val_loss: 0.0049 - val_mae: 0.0648\n",
      "Epoch 106/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0043 - mae: 0.0630 - val_loss: 0.0049 - val_mae: 0.0646\n",
      "Epoch 107/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0043 - mae: 0.0631 - val_loss: 0.0049 - val_mae: 0.0643\n",
      "Epoch 108/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0042 - mae: 0.0622 - val_loss: 0.0049 - val_mae: 0.0639\n",
      "Epoch 109/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0043 - mae: 0.0624 - val_loss: 0.0048 - val_mae: 0.0636\n",
      "Epoch 110/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0043 - mae: 0.0620 - val_loss: 0.0048 - val_mae: 0.0635\n",
      "Epoch 111/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0042 - mae: 0.0617 - val_loss: 0.0048 - val_mae: 0.0632\n",
      "Epoch 112/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0043 - mae: 0.0619 - val_loss: 0.0048 - val_mae: 0.0629\n",
      "Epoch 113/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.0042 - mae: 0.0613 - val_loss: 0.0047 - val_mae: 0.0625\n",
      "Epoch 114/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 0.0041 - mae: 0.0604 - val_loss: 0.0047 - val_mae: 0.0620\n",
      "Epoch 115/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0041 - mae: 0.0604 - val_loss: 0.0047 - val_mae: 0.0621\n",
      "Epoch 116/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0041 - mae: 0.0604 - val_loss: 0.0047 - val_mae: 0.0617\n",
      "Epoch 117/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0041 - mae: 0.0606 - val_loss: 0.0047 - val_mae: 0.0616\n",
      "Epoch 118/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0041 - mae: 0.0599 - val_loss: 0.0046 - val_mae: 0.0614\n",
      "Epoch 119/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0040 - mae: 0.0596 - val_loss: 0.0046 - val_mae: 0.0612\n",
      "Epoch 120/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0041 - mae: 0.0598 - val_loss: 0.0046 - val_mae: 0.0613\n",
      "Epoch 121/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0040 - mae: 0.0588 - val_loss: 0.0046 - val_mae: 0.0606\n",
      "Epoch 122/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0040 - mae: 0.0591 - val_loss: 0.0046 - val_mae: 0.0604\n",
      "Epoch 123/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0040 - mae: 0.0586 - val_loss: 0.0045 - val_mae: 0.0601\n",
      "Epoch 124/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 0.0040 - mae: 0.0586 - val_loss: 0.0045 - val_mae: 0.0603\n",
      "Epoch 125/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0039 - mae: 0.0581 - val_loss: 0.0045 - val_mae: 0.0598\n",
      "Epoch 126/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0039 - mae: 0.0581 - val_loss: 0.0045 - val_mae: 0.0597\n",
      "Epoch 127/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - loss: 0.0040 - mae: 0.0583 - val_loss: 0.0045 - val_mae: 0.0595\n",
      "Epoch 128/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0039 - mae: 0.0575 - val_loss: 0.0045 - val_mae: 0.0591\n",
      "Epoch 129/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 0.0039 - mae: 0.0576 - val_loss: 0.0044 - val_mae: 0.0591\n",
      "Epoch 130/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 0.0039 - mae: 0.0575 - val_loss: 0.0044 - val_mae: 0.0589\n",
      "Epoch 131/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - loss: 0.0039 - mae: 0.0578 - val_loss: 0.0044 - val_mae: 0.0587\n",
      "Epoch 132/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0039 - mae: 0.0571 - val_loss: 0.0044 - val_mae: 0.0589\n",
      "Epoch 133/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - loss: 0.0038 - mae: 0.0564 - val_loss: 0.0044 - val_mae: 0.0584\n",
      "Epoch 134/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0039 - mae: 0.0569 - val_loss: 0.0044 - val_mae: 0.0585\n",
      "Epoch 135/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0039 - mae: 0.0568 - val_loss: 0.0044 - val_mae: 0.0583\n",
      "Epoch 136/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0039 - mae: 0.0566 - val_loss: 0.0043 - val_mae: 0.0577\n",
      "Epoch 137/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0037 - mae: 0.0559 - val_loss: 0.0043 - val_mae: 0.0578\n",
      "Epoch 138/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0037 - mae: 0.0558 - val_loss: 0.0043 - val_mae: 0.0576\n",
      "Epoch 139/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0038 - mae: 0.0558 - val_loss: 0.0043 - val_mae: 0.0577\n",
      "Epoch 140/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0038 - mae: 0.0561 - val_loss: 0.0043 - val_mae: 0.0572\n",
      "Epoch 141/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0038 - mae: 0.0561 - val_loss: 0.0043 - val_mae: 0.0572\n",
      "Epoch 142/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0037 - mae: 0.0555 - val_loss: 0.0043 - val_mae: 0.0571\n",
      "Epoch 143/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0037 - mae: 0.0552 - val_loss: 0.0043 - val_mae: 0.0569\n",
      "Epoch 144/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0037 - mae: 0.0553 - val_loss: 0.0043 - val_mae: 0.0568\n",
      "Epoch 145/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0037 - mae: 0.0552 - val_loss: 0.0043 - val_mae: 0.0568\n",
      "Epoch 146/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0037 - mae: 0.0545 - val_loss: 0.0042 - val_mae: 0.0564\n",
      "Epoch 147/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.0037 - mae: 0.0551 - val_loss: 0.0043 - val_mae: 0.0567\n",
      "Epoch 148/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 0.0038 - mae: 0.0551 - val_loss: 0.0042 - val_mae: 0.0563\n",
      "Epoch 149/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0036 - mae: 0.0544 - val_loss: 0.0042 - val_mae: 0.0563\n",
      "Epoch 150/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0037 - mae: 0.0545 - val_loss: 0.0042 - val_mae: 0.0562\n",
      "Epoch 151/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - loss: 0.0037 - mae: 0.0549 - val_loss: 0.0042 - val_mae: 0.0562\n",
      "Epoch 152/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 162ms/step - loss: 0.0037 - mae: 0.0544 - val_loss: 0.0042 - val_mae: 0.0559\n",
      "Epoch 153/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 0.0036 - mae: 0.0540 - val_loss: 0.0042 - val_mae: 0.0559\n",
      "Epoch 154/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0036 - mae: 0.0539 - val_loss: 0.0042 - val_mae: 0.0557\n",
      "Epoch 155/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0037 - mae: 0.0541 - val_loss: 0.0042 - val_mae: 0.0555\n",
      "Epoch 156/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 0.0036 - mae: 0.0535 - val_loss: 0.0042 - val_mae: 0.0554\n",
      "Epoch 157/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0036 - mae: 0.0535 - val_loss: 0.0042 - val_mae: 0.0553\n",
      "Epoch 158/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0035 - mae: 0.0529 - val_loss: 0.0041 - val_mae: 0.0552\n",
      "Epoch 159/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0036 - mae: 0.0537 - val_loss: 0.0042 - val_mae: 0.0553\n",
      "Epoch 160/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 0.0036 - mae: 0.0531 - val_loss: 0.0041 - val_mae: 0.0549\n",
      "Epoch 161/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0036 - mae: 0.0536 - val_loss: 0.0041 - val_mae: 0.0550\n",
      "Epoch 162/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 0.0036 - mae: 0.0533 - val_loss: 0.0041 - val_mae: 0.0551\n",
      "Epoch 163/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0036 - mae: 0.0531 - val_loss: 0.0041 - val_mae: 0.0549\n",
      "Epoch 164/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0036 - mae: 0.0532 - val_loss: 0.0041 - val_mae: 0.0549\n",
      "Epoch 165/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0036 - mae: 0.0528 - val_loss: 0.0041 - val_mae: 0.0545\n",
      "Epoch 166/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0036 - mae: 0.0530 - val_loss: 0.0041 - val_mae: 0.0546\n",
      "Epoch 167/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0035 - mae: 0.0526 - val_loss: 0.0041 - val_mae: 0.0545\n",
      "Epoch 168/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0035 - mae: 0.0527 - val_loss: 0.0041 - val_mae: 0.0544\n",
      "Epoch 169/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0035 - mae: 0.0524 - val_loss: 0.0041 - val_mae: 0.0543\n",
      "Epoch 170/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0035 - mae: 0.0526 - val_loss: 0.0041 - val_mae: 0.0541\n",
      "Epoch 171/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0036 - mae: 0.0527 - val_loss: 0.0041 - val_mae: 0.0541\n",
      "Epoch 172/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0036 - mae: 0.0527 - val_loss: 0.0041 - val_mae: 0.0541\n",
      "Epoch 173/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0035 - mae: 0.0523 - val_loss: 0.0041 - val_mae: 0.0540\n",
      "Epoch 174/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0034 - mae: 0.0517 - val_loss: 0.0040 - val_mae: 0.0538\n",
      "Epoch 175/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0036 - mae: 0.0527 - val_loss: 0.0041 - val_mae: 0.0540\n",
      "Epoch 176/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0035 - mae: 0.0517 - val_loss: 0.0040 - val_mae: 0.0536\n",
      "Epoch 177/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0034 - mae: 0.0517 - val_loss: 0.0041 - val_mae: 0.0538\n",
      "Epoch 178/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0035 - mae: 0.0519 - val_loss: 0.0041 - val_mae: 0.0538\n",
      "Epoch 179/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0034 - mae: 0.0512 - val_loss: 0.0040 - val_mae: 0.0536\n",
      "Epoch 180/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0034 - mae: 0.0516 - val_loss: 0.0040 - val_mae: 0.0536\n",
      "Epoch 181/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0034 - mae: 0.0513 - val_loss: 0.0040 - val_mae: 0.0533\n",
      "Epoch 182/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0035 - mae: 0.0516 - val_loss: 0.0040 - val_mae: 0.0534\n",
      "Epoch 183/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0035 - mae: 0.0518 - val_loss: 0.0040 - val_mae: 0.0532\n",
      "Epoch 184/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0033 - mae: 0.0508 - val_loss: 0.0040 - val_mae: 0.0533\n",
      "Epoch 185/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0035 - mae: 0.0516 - val_loss: 0.0040 - val_mae: 0.0535\n",
      "Epoch 186/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0034 - mae: 0.0508 - val_loss: 0.0040 - val_mae: 0.0533\n",
      "Epoch 187/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0034 - mae: 0.0510 - val_loss: 0.0040 - val_mae: 0.0531\n",
      "Epoch 188/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0034 - mae: 0.0508 - val_loss: 0.0040 - val_mae: 0.0528\n",
      "Epoch 189/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0035 - mae: 0.0515 - val_loss: 0.0040 - val_mae: 0.0532\n",
      "Epoch 190/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0034 - mae: 0.0509 - val_loss: 0.0040 - val_mae: 0.0531\n",
      "Epoch 191/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0033 - mae: 0.0507 - val_loss: 0.0040 - val_mae: 0.0528\n",
      "Epoch 192/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0033 - mae: 0.0506 - val_loss: 0.0040 - val_mae: 0.0530\n",
      "Epoch 193/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0034 - mae: 0.0509 - val_loss: 0.0040 - val_mae: 0.0528\n",
      "Epoch 194/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0034 - mae: 0.0509 - val_loss: 0.0040 - val_mae: 0.0528\n",
      "Epoch 195/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0034 - mae: 0.0511 - val_loss: 0.0040 - val_mae: 0.0529\n",
      "Epoch 196/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0034 - mae: 0.0507 - val_loss: 0.0040 - val_mae: 0.0528\n",
      "Epoch 197/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 0.0034 - mae: 0.0509 - val_loss: 0.0040 - val_mae: 0.0526\n",
      "Epoch 198/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0034 - mae: 0.0509 - val_loss: 0.0040 - val_mae: 0.0527\n",
      "Epoch 199/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0034 - mae: 0.0507 - val_loss: 0.0040 - val_mae: 0.0526\n",
      "Epoch 200/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0034 - mae: 0.0510 - val_loss: 0.0040 - val_mae: 0.0526\n",
      "Epoch 201/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0034 - mae: 0.0506 - val_loss: 0.0040 - val_mae: 0.0524\n",
      "Epoch 202/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.0033 - mae: 0.0503 - val_loss: 0.0040 - val_mae: 0.0526\n",
      "Epoch 203/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0033 - mae: 0.0501 - val_loss: 0.0040 - val_mae: 0.0523\n",
      "Epoch 204/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0034 - mae: 0.0506 - val_loss: 0.0040 - val_mae: 0.0524\n",
      "Epoch 205/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0033 - mae: 0.0503 - val_loss: 0.0040 - val_mae: 0.0525\n",
      "Epoch 206/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0034 - mae: 0.0503 - val_loss: 0.0040 - val_mae: 0.0525\n",
      "Epoch 207/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0033 - mae: 0.0497 - val_loss: 0.0040 - val_mae: 0.0525\n",
      "Epoch 208/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - loss: 0.0034 - mae: 0.0506 - val_loss: 0.0040 - val_mae: 0.0523\n",
      "Epoch 209/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0034 - mae: 0.0504 - val_loss: 0.0040 - val_mae: 0.0524\n",
      "Epoch 210/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0034 - mae: 0.0502 - val_loss: 0.0040 - val_mae: 0.0524\n",
      "Epoch 211/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0033 - mae: 0.0501 - val_loss: 0.0040 - val_mae: 0.0524\n",
      "Epoch 212/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0033 - mae: 0.0497 - val_loss: 0.0040 - val_mae: 0.0521\n",
      "Epoch 213/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0034 - mae: 0.0505 - val_loss: 0.0040 - val_mae: 0.0522\n",
      "Epoch 214/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0033 - mae: 0.0501 - val_loss: 0.0040 - val_mae: 0.0521\n",
      "Epoch 215/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0033 - mae: 0.0500 - val_loss: 0.0040 - val_mae: 0.0521\n",
      "Epoch 216/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0033 - mae: 0.0498 - val_loss: 0.0039 - val_mae: 0.0520\n",
      "Epoch 217/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0033 - mae: 0.0495 - val_loss: 0.0039 - val_mae: 0.0519\n",
      "Epoch 218/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0033 - mae: 0.0497 - val_loss: 0.0039 - val_mae: 0.0519\n",
      "Epoch 219/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0033 - mae: 0.0500 - val_loss: 0.0039 - val_mae: 0.0520\n",
      "Epoch 220/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0033 - mae: 0.0496 - val_loss: 0.0039 - val_mae: 0.0520\n",
      "Epoch 221/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - loss: 0.0033 - mae: 0.0497 - val_loss: 0.0040 - val_mae: 0.0521\n",
      "Epoch 222/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 0.0033 - mae: 0.0497 - val_loss: 0.0039 - val_mae: 0.0518\n",
      "Epoch 223/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0033 - mae: 0.0499 - val_loss: 0.0039 - val_mae: 0.0518\n",
      "Epoch 224/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0033 - mae: 0.0494 - val_loss: 0.0039 - val_mae: 0.0519\n",
      "Epoch 225/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0033 - mae: 0.0495 - val_loss: 0.0039 - val_mae: 0.0517\n",
      "Epoch 226/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0033 - mae: 0.0498 - val_loss: 0.0039 - val_mae: 0.0518\n",
      "Epoch 227/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0033 - mae: 0.0493 - val_loss: 0.0039 - val_mae: 0.0517\n",
      "Epoch 228/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0033 - mae: 0.0496 - val_loss: 0.0039 - val_mae: 0.0517\n",
      "Epoch 229/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - loss: 0.0033 - mae: 0.0495 - val_loss: 0.0039 - val_mae: 0.0517\n",
      "Epoch 230/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0033 - mae: 0.0494 - val_loss: 0.0039 - val_mae: 0.0516\n",
      "Epoch 231/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0033 - mae: 0.0495 - val_loss: 0.0039 - val_mae: 0.0517\n",
      "Epoch 232/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0033 - mae: 0.0493 - val_loss: 0.0039 - val_mae: 0.0518\n",
      "Epoch 233/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0033 - mae: 0.0496 - val_loss: 0.0039 - val_mae: 0.0515\n",
      "Epoch 234/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0033 - mae: 0.0495 - val_loss: 0.0039 - val_mae: 0.0516\n",
      "Epoch 235/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0032 - mae: 0.0492 - val_loss: 0.0039 - val_mae: 0.0516\n",
      "Epoch 236/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0033 - mae: 0.0494 - val_loss: 0.0039 - val_mae: 0.0517\n",
      "Epoch 237/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0032 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0514\n",
      "Epoch 238/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0032 - mae: 0.0490 - val_loss: 0.0039 - val_mae: 0.0515\n",
      "Epoch 239/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0033 - mae: 0.0493 - val_loss: 0.0039 - val_mae: 0.0515\n",
      "Epoch 240/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0032 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0515\n",
      "Epoch 241/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0032 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0515\n",
      "Epoch 242/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0033 - mae: 0.0492 - val_loss: 0.0039 - val_mae: 0.0514\n",
      "Epoch 243/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.0033 - mae: 0.0491 - val_loss: 0.0039 - val_mae: 0.0515\n",
      "Epoch 244/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0032 - mae: 0.0487 - val_loss: 0.0039 - val_mae: 0.0515\n",
      "Epoch 245/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0033 - mae: 0.0493 - val_loss: 0.0039 - val_mae: 0.0515\n",
      "Epoch 246/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.0033 - mae: 0.0494 - val_loss: 0.0039 - val_mae: 0.0515\n",
      "Epoch 247/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0032 - mae: 0.0488 - val_loss: 0.0039 - val_mae: 0.0514\n",
      "Epoch 248/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0033 - mae: 0.0491 - val_loss: 0.0039 - val_mae: 0.0515\n",
      "Epoch 249/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0033 - mae: 0.0495 - val_loss: 0.0039 - val_mae: 0.0514\n",
      "Epoch 250/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0514\n",
      "Epoch 251/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0033 - mae: 0.0492 - val_loss: 0.0039 - val_mae: 0.0513\n",
      "Epoch 252/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0032 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0514\n",
      "Epoch 253/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0032 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0513\n",
      "Epoch 254/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0033 - mae: 0.0491 - val_loss: 0.0039 - val_mae: 0.0513\n",
      "Epoch 255/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0513\n",
      "Epoch 256/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0032 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0513\n",
      "Epoch 257/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0032 - mae: 0.0485 - val_loss: 0.0039 - val_mae: 0.0513\n",
      "Epoch 258/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0033 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0513\n",
      "Epoch 259/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0512\n",
      "Epoch 260/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0032 - mae: 0.0485 - val_loss: 0.0039 - val_mae: 0.0513\n",
      "Epoch 261/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0514\n",
      "Epoch 262/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0513\n",
      "Epoch 263/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0033 - mae: 0.0490 - val_loss: 0.0039 - val_mae: 0.0512\n",
      "Epoch 264/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.0032 - mae: 0.0488 - val_loss: 0.0039 - val_mae: 0.0513\n",
      "Epoch 265/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0033 - mae: 0.0490 - val_loss: 0.0039 - val_mae: 0.0512\n",
      "Epoch 266/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0039 - val_mae: 0.0511\n",
      "Epoch 267/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0032 - mae: 0.0487 - val_loss: 0.0039 - val_mae: 0.0511\n",
      "Epoch 268/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0032 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0511\n",
      "Epoch 269/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0032 - mae: 0.0487 - val_loss: 0.0039 - val_mae: 0.0511\n",
      "Epoch 270/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0512\n",
      "Epoch 271/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0032 - mae: 0.0487 - val_loss: 0.0039 - val_mae: 0.0511\n",
      "Epoch 272/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0509\n",
      "Epoch 273/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0032 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0512\n",
      "Epoch 274/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0039 - val_mae: 0.0511\n",
      "Epoch 275/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0032 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0511\n",
      "Epoch 276/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0032 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0511\n",
      "Epoch 277/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0039 - val_mae: 0.0510\n",
      "Epoch 278/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0039 - val_mae: 0.0511\n",
      "Epoch 279/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0031 - mae: 0.0479 - val_loss: 0.0039 - val_mae: 0.0510\n",
      "Epoch 280/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0032 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0510\n",
      "Epoch 281/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0039 - val_mae: 0.0510\n",
      "Epoch 282/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0039 - val_mae: 0.0510\n",
      "Epoch 283/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0039 - val_mae: 0.0510\n",
      "Epoch 284/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0032 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0511\n",
      "Epoch 285/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0510\n",
      "Epoch 286/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0032 - mae: 0.0481 - val_loss: 0.0039 - val_mae: 0.0509\n",
      "Epoch 287/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0508\n",
      "Epoch 288/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0039 - val_mae: 0.0509\n",
      "Epoch 289/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0031 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0510\n",
      "Epoch 290/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0031 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0509\n",
      "Epoch 291/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0509\n",
      "Epoch 292/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0031 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0509\n",
      "Epoch 293/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0031 - mae: 0.0481 - val_loss: 0.0039 - val_mae: 0.0509\n",
      "Epoch 294/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 0.0032 - mae: 0.0481 - val_loss: 0.0039 - val_mae: 0.0509\n",
      "Epoch 295/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0509\n",
      "Epoch 296/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0032 - mae: 0.0485 - val_loss: 0.0039 - val_mae: 0.0509\n",
      "Epoch 297/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0039 - val_mae: 0.0507\n",
      "Epoch 298/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 0.0032 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0508\n",
      "Epoch 299/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0507\n",
      "Epoch 300/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - loss: 0.0032 - mae: 0.0481 - val_loss: 0.0039 - val_mae: 0.0509\n",
      "Epoch 301/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0032 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0509\n",
      "Epoch 302/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0039 - val_mae: 0.0508\n",
      "Epoch 303/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0039 - val_mae: 0.0508\n",
      "Epoch 304/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0031 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0508\n",
      "Epoch 305/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0032 - mae: 0.0481 - val_loss: 0.0039 - val_mae: 0.0508\n",
      "Epoch 306/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.0032 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0508\n",
      "Epoch 307/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0507\n",
      "Epoch 308/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0507\n",
      "Epoch 309/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0031 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0508\n",
      "Epoch 310/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0031 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0507\n",
      "Epoch 311/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - loss: 0.0032 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0508\n",
      "Epoch 312/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0031 - mae: 0.0479 - val_loss: 0.0039 - val_mae: 0.0508\n",
      "Epoch 313/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - loss: 0.0031 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0508\n",
      "Epoch 314/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0507\n",
      "Epoch 315/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0039 - val_mae: 0.0507\n",
      "Epoch 316/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 317/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0507\n",
      "Epoch 318/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 319/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 320/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0030 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 321/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0032 - mae: 0.0481 - val_loss: 0.0039 - val_mae: 0.0507\n",
      "Epoch 322/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 323/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 324/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 325/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - loss: 0.0031 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 326/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 327/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 328/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 329/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0032 - mae: 0.0479 - val_loss: 0.0039 - val_mae: 0.0507\n",
      "Epoch 330/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 331/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 332/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0507\n",
      "Epoch 333/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0039 - val_mae: 0.0507\n",
      "Epoch 334/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 335/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0030 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 336/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0030 - mae: 0.0471 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 337/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 338/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0507\n",
      "Epoch 339/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 340/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 341/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0030 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 342/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 343/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 344/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0030 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 345/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0031 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 346/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 347/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 348/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 349/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 350/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.0030 - mae: 0.0469 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 351/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.0030 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 352/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 353/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0031 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 354/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0030 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 355/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0030 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 356/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0030 - mae: 0.0469 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 357/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 358/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0039 - val_mae: 0.0506\n",
      "Epoch 359/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0030 - mae: 0.0469 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 360/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 361/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 362/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 363/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 364/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 365/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 366/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 367/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 368/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 369/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0031 - mae: 0.0469 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 370/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 371/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0030 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 372/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 373/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 374/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 375/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 376/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0030 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 377/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 378/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 379/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 380/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0029 - mae: 0.0461 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 381/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 382/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 383/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 384/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 385/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 386/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 387/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 0.0030 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 388/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 389/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 390/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 391/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0030 - mae: 0.0469 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 392/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0030 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0505\n",
      "Epoch 393/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 394/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 395/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 396/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 397/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 398/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0030 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 399/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0029 - mae: 0.0461 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 400/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 401/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 402/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 403/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 404/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 405/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 406/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 407/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0504\n",
      "Epoch 408/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 409/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.0029 - mae: 0.0460 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 410/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 411/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0029 - mae: 0.0457 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 412/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 0.0030 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 413/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 414/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 162ms/step - loss: 0.0029 - mae: 0.0461 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 415/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 416/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 417/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 418/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 419/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 126ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 420/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 421/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 139ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 422/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 423/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 424/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0502\n",
      "Epoch 425/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 426/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0029 - mae: 0.0461 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 427/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 428/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0029 - mae: 0.0460 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 429/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0029 - mae: 0.0458 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 430/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 431/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0029 - mae: 0.0460 - val_loss: 0.0039 - val_mae: 0.0502\n",
      "Epoch 432/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 433/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0029 - mae: 0.0457 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 434/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0029 - mae: 0.0459 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 435/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0029 - mae: 0.0460 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 436/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 437/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 438/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0039 - val_mae: 0.0502\n",
      "Epoch 439/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0029 - mae: 0.0459 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 440/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0029 - mae: 0.0460 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 441/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 442/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 443/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 444/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 445/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0029 - mae: 0.0458 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 446/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0029 - mae: 0.0459 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 447/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0039 - val_mae: 0.0502\n",
      "Epoch 448/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 449/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 450/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.0029 - mae: 0.0461 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 451/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 452/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - loss: 0.0029 - mae: 0.0459 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 453/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 454/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 455/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - loss: 0.0029 - mae: 0.0459 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 456/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 457/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 458/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 459/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 460/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.0029 - mae: 0.0457 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 461/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0029 - mae: 0.0458 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 462/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 463/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0029 - mae: 0.0458 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 464/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0503\n",
      "Epoch 465/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 466/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0029 - mae: 0.0457 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 467/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0029 - mae: 0.0457 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 468/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0029 - mae: 0.0453 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 469/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 470/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 471/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 472/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0029 - mae: 0.0458 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 473/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 474/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0029 - mae: 0.0460 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 475/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0029 - mae: 0.0458 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 476/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0029 - mae: 0.0459 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 477/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0029 - mae: 0.0457 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 478/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 479/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0029 - mae: 0.0453 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 480/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0029 - mae: 0.0460 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 481/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0029 - mae: 0.0459 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 482/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0029 - mae: 0.0459 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 483/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - loss: 0.0029 - mae: 0.0457 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 484/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0029 - mae: 0.0453 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 485/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 486/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 487/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0029 - mae: 0.0458 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 488/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0029 - mae: 0.0460 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 489/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0038 - val_mae: 0.0501\n",
      "Epoch 490/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 491/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0038 - val_mae: 0.0501\n",
      "Epoch 492/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0038 - val_mae: 0.0501\n",
      "Epoch 493/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 494/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 495/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0029 - mae: 0.0459 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 496/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0038 - val_mae: 0.0501\n",
      "Epoch 497/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 498/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0028 - mae: 0.0451 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 499/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 500/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0029 - mae: 0.0460 - val_loss: 0.0038 - val_mae: 0.0502\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m val_loss_values \u001b[38;5;241m=\u001b[39m history_conv_rnn_model\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# validation loss\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(mae_values, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining MAE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(val_mae_values, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation MAE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
    "\n",
    "conv_rnn_model.compile(loss=tf.keras.losses.Huber(), optimizer=opt,metrics=[\"mae\"])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor=\"val_mae\", patience=50, restore_best_weights=True)\n",
    "\n",
    "history_conv_rnn_model    =   conv_rnn_model.fit(\n",
    "                                                downsampled_train, \n",
    "                                                validation_data=downsampled_valid,\n",
    "                                                epochs=500,\n",
    "                                                callbacks=[early_stopping_cb]\n",
    "        )\n",
    "# Get MAE values for training and validation\n",
    "mae_values = history_conv_rnn_model.history['mae']  # training MAE\n",
    "val_mae_values = history_conv_rnn_model.history['val_mae']  # validation MAE\n",
    "\n",
    "# Get loss values\n",
    "loss_values = history_conv_rnn_model.history['loss']  # training loss\n",
    "val_loss_values = history_conv_rnn_model.history['val_loss']  # validation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mae_values, label='Training MAE')\n",
    "plt.plot(val_mae_values, label='Validation MAE')\n",
    "plt.title('Model MAE over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from the model\n",
    "test_predictions = conv_rnn_model.predict(downsampled_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 55, 14)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample predictions\n",
    "downsampled_predictions = test_predictions[:, :, 3::2]  # Match downsampling in validation targets\n",
    "# Flatten predictions and targets\n",
    "flattened_predictions = downsampled_predictions.reshape(-1)*1e6\n",
    "flattened_targets = np.concatenate([y.numpy() for _, y in downsampled_valid])[:, :, 3::2].reshape(-1)*1e6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8580,)\n",
      "(8580,)\n",
      "(26, 55, 14)\n"
     ]
    }
   ],
   "source": [
    "print(flattened_predictions.shape)  # Should match flattened_targets.shape\n",
    "print(flattened_targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 49399.09\n"
     ]
    }
   ],
   "source": [
    "mae = np.mean(np.abs(flattened_predictions - flattened_targets))\n",
    "print(\"MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manch\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions\n",
    "test_predictions = conv_rnn_model.predict(downsampled_valid)\n",
    "\n",
    "# Since we're using a sequence length of 56, our predictions start at index 56\n",
    "# We need to align the predictions with the actual values\n",
    "actual_values = mulvar_valid[\"rail\"][112:].values\n",
    "#mae_1 = (pd.DataFrame(test_predictions*1e6) - pd.DataFrame(actual_values*1e6)).abs().mean() \n",
    "#print(mae_1)\n",
    "actual_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y can be no greater than 2D, but have shapes (26,) and (26, 55, 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPredicted values\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(actual_values, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual Values\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel MAE over Epochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3798\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3800\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\axes\\_axes.py:1779\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1779\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\axes\\_base.py:296\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    295\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\axes\\_base.py:489\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    490\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    492\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "\u001b[1;31mValueError\u001b[0m: x and y can be no greater than 2D, but have shapes (26,) and (26, 55, 14)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_predictions, label='Predicted values')\n",
    "plt.plot(actual_values, label='Actual Values')\n",
    "plt.title('Model MAE over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavenet_model = tf.keras.Sequential()\n",
    "wavenet_model.add(tf.keras.layers.Input(shape=[None, 5]))\n",
    "for rate in (1, 2, 4, 8) * 2:\n",
    "    wavenet_model.add(\n",
    "                        tf.keras.layers.Conv1D(\n",
    "                                                filters=32, \n",
    "                                                kernel_size=2, \n",
    "                                                padding=\"causal\",\n",
    "                                                activation=\"relu\",\n",
    "                                                dilation_rate=rate\n",
    "                                                )\n",
    "                        )\n",
    "    wavenet_model.add(tf.keras.layers.Conv1D(filters=14,kernel_size=1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
